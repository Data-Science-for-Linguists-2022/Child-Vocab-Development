{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0361b10a-3d8d-4fdd-876a-dd275328f930",
   "metadata": {},
   "source": [
    "\n",
    "# Data curation\n",
    "\n",
    "Man Ho Wong | m.wong@pitt.edu | Feb 27th, 2022\n",
    "\n",
    "This notebook search for the datasets needed for this project in the following databases:\n",
    "- [CHILDES](https://childes.talkbank.org/)\n",
    "- [Wordbank](http://wordbank.stanford.edu/) (I may not need this dataset as CHILBES may probably have all the data I need.)\n",
    "\n",
    "I will also explore the datasets on the way to get a sense of the contents and the structures of the datasets (such as participant information, annotations, data format, etc.), as well as some basic statistics about the datasets. After that, I will identify the information I need in the datasets and compile the data for data processing later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624715b-d6a5-41f6-b7bc-adf57127d855",
   "metadata": {},
   "source": [
    "\n",
    "# 1 CHILDES\n",
    "\n",
    "CHILDES Intro, format, example etc.\n",
    "\n",
    "For this project, I will need to collect the transcipts for both the child speech and the child-directed speech (CDS). Additionally, I will need the participant information (i.e. child age, sex and socioeconomic status (SES), mother's education) and some basic annotations of the words (i.e. morphemes and lexical categories). Participant information can be found in the header of each CHAT file as the metadata of the file. Annotation information can be found as dependent tiers embedded in the transcription.\n",
    "\n",
    "I will first search for the datasets meeting the needs of the project. Here are the basic search criteria:\n",
    "- Language: North American English (Note: I may need other languages later for comparison)\n",
    "- Participants: contains only child and mother (i.e. other people such as investigators were not involved)\n",
    "- Child information: contains child age, sex and socioeconomic status (SES)\n",
    "- Mother information: contains socioeconomic status (SES), education\n",
    "- Annotation: contains morpheme and/or grammatical tiers\n",
    "\n",
    "Let's take a quick look at a sample CHAT file first to see how the data is organized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98686cc-77f7-4f43-91dd-4575e7261f98",
   "metadata": {},
   "source": [
    "\n",
    "## 1.1 Reading CHAT file\n",
    "\n",
    "The `PyLangAcq` package allows users to read CHAT files directly from a zip file. You can download and install it with the following code:  \n",
    "`$ pip install --upgrade pylangacq`\n",
    "\n",
    "For documentation, you can visit their [website](https://pylangacq.org/).\n",
    "\n",
    "I will use the Brown Corpus of CHILDES as an example below. The corpus has been downloaded from [here](https://childes.talkbank.org/data/Eng-NA/Brown.zip) and stored under `data_samples/childes/Brown.zip`. There are three folders in this corpus, each folder contains a dataset (a collection of CHAT files) for each child:\n",
    "\n",
    "```\n",
    "Brown.zip/  \n",
    "    |--Adam/  \n",
    "    |--Eve/  \n",
    "    |--Sarah/\n",
    "```\n",
    "\n",
    "I will use the `read_chat()` function of `PyLangAcq` to read all the CHAT files in the dataset `Adam`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9e997b-a6eb-4ede-b8d2-eba6cc55bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pylangacq.chat.Reader'>\n",
      "Number of CHAT files: 55\n"
     ]
    }
   ],
   "source": [
    "import pylangacq\n",
    "\n",
    "# Read CHAT files in the dataset 'Adam' in 'Brown.zip':\n",
    "path = 'data_samples/childes/Brown.zip'\n",
    "adam = pylangacq.read_chat(path, 'Adam')\n",
    "\n",
    "print(type(adam))\n",
    "print('Number of CHAT files:', adam.n_files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda0575c-87d5-458f-915e-47a7737f4bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages (year, month, day): [(2, 3, 4), (2, 3, 18), (2, 4, 3), (2, 4, 15), (2, 4, 30), (2, 5, 12), (2, 6, 3), (2, 6, 17), (2, 7, 1), (2, 7, 14), (2, 8, 1), (2, 8, 16), (2, 9, 4), (2, 9, 18), (2, 10, 2), (2, 10, 16), (2, 10, 30), (2, 11, 13), (2, 11, 28), (3, 0, 11), (3, 0, 25), (3, 1, 9), (3, 1, 26), (3, 2, 9), (3, 2, 21), (3, 3, 4), (3, 3, 18), (3, 4, 1), (3, 4, 18), (3, 5, 1), (3, 5, 15), (3, 5, 29), (3, 6, 9), (3, 7, 7), (3, 8, 1), (3, 8, 14), (3, 8, 26), (3, 9, 16), (3, 10, 15), (3, 11, 1), (3, 11, 14), (4, 0, 14), (4, 1, 15), (4, 2, 17), (4, 3, 9), (4, 4, 1), (4, 4, 13), (4, 5, 11), (4, 6, 24), (4, 7, 1), (4, 7, 29), (4, 9, 2), (4, 10, 2), (4, 10, 23), (5, 2, 12)]\n"
     ]
    }
   ],
   "source": [
    "# Ages when recordings were made\n",
    "print('Ages (year, month, day):', adam.ages())  # output: a list of tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f47d0-163c-498c-81a2-7828c9270d7d",
   "metadata": {},
   "source": [
    "As shown above, `read_chat()` read the CHAT files and creates a `Reader` object. This is a `dataclass` storing data and metadata across all the CHAT files in `Adam`. You can access the data stored in the `Reader` by calling the appropriate methods, such as `.n_files()` for number of CHAT files in the dataset. For example, `Adam` has 55 CHAT files. We can also get the ages when recordings were made by calling `.ages()`. Let's see what other information we can get from the `Reader` object in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97d197-845e-46e4-a494-cd3765572cb0",
   "metadata": {},
   "source": [
    "## 1.2 Accessing metadata stored in a CHAT file\n",
    "\n",
    "Metadata such as age range, date of recording, participants, etc. are stored in the header of each CHAT file. We can access these information by calling the `.header()` method. Here is the header for the first CHAT file in `adam`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caad807e-c699-4e50-9dfc-f9663e6c8f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UTF8': '',\n",
       " 'PID': '11312/c-00015632-1',\n",
       " 'Languages': ['eng'],\n",
       " 'Participants': {'CHI': {'name': 'Adam',\n",
       "   'language': 'eng',\n",
       "   'corpus': 'Brown',\n",
       "   'age': '2;03.04',\n",
       "   'sex': 'male',\n",
       "   'group': 'TD',\n",
       "   'ses': 'MC',\n",
       "   'role': 'Target_Child',\n",
       "   'education': '',\n",
       "   'custom': ''},\n",
       "  'MOT': {'name': 'Mother',\n",
       "   'language': 'eng',\n",
       "   'corpus': 'Brown',\n",
       "   'age': '',\n",
       "   'sex': 'female',\n",
       "   'group': '',\n",
       "   'ses': '',\n",
       "   'role': 'Mother',\n",
       "   'education': '',\n",
       "   'custom': ''},\n",
       "  'URS': {'name': 'Ursula_Bellugi',\n",
       "   'language': 'eng',\n",
       "   'corpus': 'Brown',\n",
       "   'age': '',\n",
       "   'sex': '',\n",
       "   'group': '',\n",
       "   'ses': '',\n",
       "   'role': 'Investigator',\n",
       "   'education': '',\n",
       "   'custom': ''},\n",
       "  'RIC': {'name': 'Richard_Cromer',\n",
       "   'language': 'eng',\n",
       "   'corpus': 'Brown',\n",
       "   'age': '',\n",
       "   'sex': '',\n",
       "   'group': '',\n",
       "   'ses': '',\n",
       "   'role': 'Investigator',\n",
       "   'education': '',\n",
       "   'custom': ''},\n",
       "  'COL': {'name': 'Colin_Fraser',\n",
       "   'language': 'eng',\n",
       "   'corpus': 'Brown',\n",
       "   'age': '',\n",
       "   'sex': '',\n",
       "   'group': '',\n",
       "   'ses': '',\n",
       "   'role': 'Investigator',\n",
       "   'education': '',\n",
       "   'custom': ''}},\n",
       " 'Date': {datetime.date(1962, 10, 8), datetime.date(1962, 10, 9)},\n",
       " 'Comment': 'Birth of CHI is 4-JUL-1960',\n",
       " 'Time Duration': '15:00-16:00',\n",
       " 'Types': 'long, toyplay, TD'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.headers()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29beeb4-d948-4c36-b2f3-eab0a9095ffb",
   "metadata": {},
   "source": [
    "The output above, is a multilevel `dictionary`. TO retrieve a specific piece of information we need, we can use the `dictionary` keys as usual.  \n",
    "Let's check if 'Adam' is a male as its biblical name suggests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4850e46-5e97-4e20-8a06-6aea94ef4090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.headers()[0]['Participants']['CHI']['sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9708f-391c-4edf-a245-25e4c2d06095",
   "metadata": {},
   "source": [
    "\n",
    "## 1.3 Accessing annotations\n",
    "\n",
    "Next, I will check what kinds of annotation information are stored in each CHAT file. I will use the `.tokens()` method to access the tokens with annotation information. This method creates a `list` of `Token` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d0375c-caed-42a4-9afc-d121b3f79e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(word='play', pos='n', mor='play', gra=Gra(dep=1, head=2, rel='MOD')),\n",
       " Token(word='checkers', pos='n', mor='checker-PL', gra=Gra(dep=2, head=0, rel='INCROOT')),\n",
       " Token(word='.', pos='.', mor='', gra=Gra(dep=3, head=2, rel='PUNCT')),\n",
       " Token(word='big', pos='adj', mor='big', gra=Gra(dep=1, head=2, rel='MOD')),\n",
       " Token(word='drum', pos='n', mor='drum', gra=Gra(dep=2, head=0, rel='INCROOT'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = adam.tokens()\n",
    "tokens[:5]  # first five tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f07287-85f1-45ef-8234-a647f9a4fd24",
   "metadata": {},
   "source": [
    "Each `Token` is a `dataclass` with attributes (e.g. `word`,`pos`, etc.) as shown in the above example.  \n",
    "Annotations for each word are stored as the `Token`'s attributes (i.e. attributes other than `word`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2bf4834-9464-4b45-9c7e-3d8074646518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second token in 'Adam':\n",
      "Word: checkers\n",
      "Morpheme: checker-PL\n",
      "Part of speech: n\n"
     ]
    }
   ],
   "source": [
    "print(\"Second token in 'Adam':\")\n",
    "print('Word: {}\\nMorpheme: {}\\nPart of speech: {}'.format(\n",
    "    tokens[1].word, tokens[1].mor, tokens[1].pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a51c99-28b0-4d98-97ec-8a61817ab671",
   "metadata": {},
   "source": [
    "\n",
    "## 1.4 Searching for suitable datasets\n",
    "\n",
    "Now that we know what kinds of information are stored in each dataset and how we can access them, we can start searching for the datasets for the project according to the criteria set previously.\n",
    "\n",
    "There are dozens of English corpora in CHILDES. We don't need to download them all at once just to look for the corpora we need. `PyLangAcq` allows user to read a corpus directly with the corpus's URL. We can read the corpora one by one, and keep only the ones we need. To get the URLs for all the North American English corpora, one can use some web scraping tools to get all the links from the database's website and look for the corpus URLs from there. However, a much faster way is to take advantage of the TalkBank's [browsable database](https://sla.talkbank.org/TBB/childes):  \n",
    "1. navigate to CHILDES's North American English datasets (Eng-NA)\n",
    "2. copy the list of corpora directly to a spreadsheet program and save it as a `csv` file (example: `data_samples/childes/eng_NA_corpus_list.csv`)\n",
    "3. construct the URL for each corpus simply from the name of the corpus we get from step 2 (see below)\n",
    "\n",
    "CHILDES has a very well organized structure. Each corpus has the same URL format as follow:  \n",
    "`https://childes.talkbank.org/data/LANGUAGE/NAME_OF_CORPUS.zip`  \n",
    "For example, the URL for the Brown Corpus is: https://childes.talkbank.org/data/Eng-NA/Brown.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7132000-53ab-4b6b-b187-4f647de52636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 NA English corpora in CHILDES.\n",
      "Here are the first 10 corpora:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        Bates\n",
       "1    Bernstein\n",
       "2        Bliss\n",
       "3        Bloom\n",
       "4     Bohannon\n",
       "5    Braunwald\n",
       "6        Brent\n",
       "7        Brown\n",
       "8        Clark\n",
       "9    Demetras1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the list of corpora into a Pandas Series:\n",
    "corpus_list = pd.read_csv('data/childes/eng_NA_corpus_list.csv', \n",
    "                          header=None, index_col=False, squeeze = True)\n",
    "\n",
    "print('There are {} NA English corpora in CHILDES.'.format(len(corpus_list)))\n",
    "print('Here are the first 10 corpora:')\n",
    "corpus_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d611aa-aa63-4fac-8306-a8e25464cd0a",
   "metadata": {},
   "source": [
    "Let's try to search the corpora matching some of the criteria set previously, e.g. corpora containing information about child's/ mother's SES and educational background. As shown previously, we can use `.headers` to access these information in the CHAT files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a43cb57-1335-432f-9ba8-bbb473cf9de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Bates...\n",
      "Bates matches the criteria!\n",
      "\n",
      "Searching Bernstein...\n",
      "Bernstein matches the criteria!\n",
      "\n",
      "Searching Bliss...\n",
      "Searching Bloom...\n",
      "Searching Bohannon...\n",
      "Searching Braunwald...\n",
      "Searching Brent...\n",
      "Searching Brown...\n",
      "Brown matches the criteria!\n",
      "\n",
      "Searching Clark...\n",
      "Clark matches the criteria!\n",
      "\n",
      "Searching Demetras1...\n",
      "Searching Demetras2...\n",
      "Demetras2 matches the criteria!\n",
      "\n",
      "Searching Evans...\n",
      "Searching Feldman...\n",
      "Searching Garvey...\n",
      "Searching Gathercole...\n",
      "Searching Gelman...\n",
      "Searching Gleason...\n",
      "Gleason matches the criteria!\n",
      "\n",
      "Searching Gopnik...\n",
      "Searching HSLLD...\n",
      "HSLLD matches the criteria!\n",
      "\n",
      "Searching Haggerty...\n",
      "Searching Hall...\n",
      "Hall matches the criteria!\n",
      "\n",
      "Searching Hicks...\n",
      "Searching Higginson...\n",
      "Searching Kuczaj...\n",
      "Searching MacWhinney...\n",
      "Searching McCune...\n",
      "Searching McMillan...\n",
      "Searching Morisset...\n",
      "Searching Nelson...\n",
      "Searching NewEngland...\n",
      "Searching NewmanRatner...\n",
      "NewmanRatner matches the criteria!\n",
      "\n",
      "Searching Peters...\n",
      "Searching PetersonMcCabe...\n",
      "Searching Post...\n",
      "Post matches the criteria!\n",
      "\n",
      "Searching Rollins...\n",
      "Searching Sachs...\n",
      "Searching Sawyer...\n",
      "Searching Snow...\n",
      "Searching Soderstrom...\n",
      "Searching Sprott...\n",
      "Searching Suppes...\n",
      "Searching Tardif...\n",
      "Searching Valian...\n",
      "Searching VanHouten...\n",
      "VanHouten matches the criteria!\n",
      "\n",
      "Searching VanKleeck...\n",
      "Searching Warren...\n",
      "Searching Weist...\n",
      "\n",
      "Corpora matching the criteria:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bates',\n",
       " 'Bernstein',\n",
       " 'Brown',\n",
       " 'Clark',\n",
       " 'Demetras2',\n",
       " 'Gleason',\n",
       " 'HSLLD',\n",
       " 'Hall',\n",
       " 'NewmanRatner',\n",
       " 'Post',\n",
       " 'VanHouten']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = []  # To store a list of corpora matching the criteria\n",
    "\n",
    "# Search each corpus in the list:\n",
    "for corpus_name in corpus_list:\n",
    "    \n",
    "    # Construct the URL for the corpus from its name:\n",
    "    corpus_url = 'https://childes.talkbank.org/data/Eng-NA/'+corpus_name+'.zip'\n",
    "    \n",
    "    # read the corpus into a Reader object:\n",
    "    print('Searching {}...'.format(corpus_name))\n",
    "    corpus = pylangacq.read_chat(corpus_url)\n",
    "    \n",
    "    # Inspect each CHAT file in the corpus:\n",
    "    found = False    \n",
    "    for file in range(corpus.n_files()):\n",
    "        \n",
    "        # Search criteria:\n",
    "        # dataset must contain only child ('CHI') and mother (MOT) as participants\n",
    "        # (as we are looking at child-directed speech). \n",
    "        # dataset must include child's or mother's SES/education.\n",
    "        if (\n",
    "            (('CHI' in corpus.headers()[file]['Participants']) and \n",
    "            ('MOT' in corpus.headers()[file]['Participants']) and\n",
    "            ('INV' not in corpus.headers()[file]['Participants'])) \n",
    "            \n",
    "            and\n",
    "            \n",
    "            ((corpus.headers()[file]['Participants']['MOT']['ses'] != '') or\n",
    "             (corpus.headers()[file]['Participants']['CHI']['ses'] != '') or\n",
    "             (corpus.headers()[file]['Participants']['MOT']['education'] != ''))\n",
    "        ):\n",
    "            \n",
    "            print('{} matches the criteria!\\n'.format(corpus_name))\n",
    "            search_result.append(corpus_name) \n",
    "            found = True\n",
    "            \n",
    "        # Break the for loop if criteria are matched and move on to another\n",
    "        # corpus. (If one CHAT file contains the needed information, I will keep\n",
    "        # the whole corpus for data processing later and remove individual CHAT\n",
    "        # files missing the needed information.)\n",
    "        if found == True:\n",
    "            break       \n",
    "\n",
    "print('\\nCorpora matching the criteria:')\n",
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff8ff5-cdcf-4b25-921e-098ba94daf7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
