{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f364fe8-c151-4f2d-922c-e7a7060930b1",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Man Ho Wong | March 21, 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504c7cb0-fdfc-44a4-bda0-bd9093ae0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries and packages required\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint                    # For pretty printing\n",
    "import pylangacq                 # For reading CHAT files\n",
    "from tqdm import tqdm            # For showing progress bar\n",
    "\n",
    "# use ggplot style for figures\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Unpickle data\n",
    "data = pickle.load(open('../data/childes/corpus_info.pkl', 'rb'))\n",
    "data_idx = data[1]\n",
    "\n",
    "# Pretty printing for better readability\n",
    "# With this, you can print dict in compact format instead of one item\n",
    "#   per line. Items will be in alphabetical order. Nested Dict will be printed \n",
    "#   with suitable indentation. It will also print Counter in descending order.\n",
    "#   To use this, call cp.pprint()\n",
    "cp = pprint.PrettyPrinter(compact=True, sort_dicts=True)\n",
    "\n",
    "# Function to get all labels of a given variable (e.g. 'mot_edu')\n",
    "def get_labels(var):\n",
    "    labels_by_corpus = {}\n",
    "    corpus_set = set(data_idx.corpus)\n",
    "    for c in corpus_set:\n",
    "        labels_by_corpus[c] = set(data_idx[var][data_idx.corpus==c])\n",
    "    return labels_by_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6f180-0a5d-4697-a35b-dbbca820e647",
   "metadata": {},
   "source": [
    "`data_idx` is a `DataFrame` created by [data_curation.ipynb](Data_Science/Child-Vocab-Development/codes/data_curation.ipynb). It contains basic information about the files in the curated dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c420575-5dab-4618-aa95-b7dd13d71a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>corpus</th>\n",
       "      <th>year</th>\n",
       "      <th>participants</th>\n",
       "      <th>name</th>\n",
       "      <th>age_d</th>\n",
       "      <th>age_m</th>\n",
       "      <th>sex</th>\n",
       "      <th>group</th>\n",
       "      <th>ses</th>\n",
       "      <th>mot_edu</th>\n",
       "      <th>situation</th>\n",
       "      <th>activities</th>\n",
       "      <th>study_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/childes/Bates/Free20/amy.cha</td>\n",
       "      <td>Bates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Target_Child</td>\n",
       "      <td>600</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>TD</td>\n",
       "      <td>MC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/childes/Bates/Free20/betty.cha</td>\n",
       "      <td>Bates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Betty</td>\n",
       "      <td>600</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>TD</td>\n",
       "      <td>MC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/childes/Bates/Free20/chuck.cha</td>\n",
       "      <td>Bates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>600</td>\n",
       "      <td>20.0</td>\n",
       "      <td>male</td>\n",
       "      <td>TD</td>\n",
       "      <td>MC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/childes/Bates/Free20/doug.cha</td>\n",
       "      <td>Bates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Doug</td>\n",
       "      <td>600</td>\n",
       "      <td>20.0</td>\n",
       "      <td>male</td>\n",
       "      <td>TD</td>\n",
       "      <td>MC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/childes/Bates/Free20/ed.cha</td>\n",
       "      <td>Bates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Ed</td>\n",
       "      <td>600</td>\n",
       "      <td>20.0</td>\n",
       "      <td>male</td>\n",
       "      <td>TD</td>\n",
       "      <td>MC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>../data/childes/VanHouten/Twos/teaching/parkt.cha</td>\n",
       "      <td>VanHouten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>840</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>MOT_Older</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>Teaching. Mother and Child sit on floor. First...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>../data/childes/VanHouten/Twos/teaching/pricet...</td>\n",
       "      <td>VanHouten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Peter</td>\n",
       "      <td>840</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>MOT_adolescent</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>Teaching. Mother and Child sit on the floor in...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>../data/childes/VanHouten/Twos/teaching/raidt.cha</td>\n",
       "      <td>VanHouten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Tommy</td>\n",
       "      <td>840</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>MOT_older</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>Teaching. Mother , Child and Father sit in liv...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>../data/childes/VanHouten/Twos/teaching/riott.cha</td>\n",
       "      <td>VanHouten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Robert</td>\n",
       "      <td>840</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>MOT_Adolescent</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>Teaching. Mother and Child sit on the living r...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>../data/childes/VanHouten/Twos/teaching/royalt...</td>\n",
       "      <td>VanHouten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{CHI, MOT}</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>840</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>MOT_Adolescent</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>Teaching. Mother and Child sit on living room ...</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, toyplay, TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2611 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_path     corpus  year  \\\n",
       "0                  ../data/childes/Bates/Free20/amy.cha      Bates   NaN   \n",
       "1                ../data/childes/Bates/Free20/betty.cha      Bates   NaN   \n",
       "2                ../data/childes/Bates/Free20/chuck.cha      Bates   NaN   \n",
       "3                 ../data/childes/Bates/Free20/doug.cha      Bates   NaN   \n",
       "4                   ../data/childes/Bates/Free20/ed.cha      Bates   NaN   \n",
       "...                                                 ...        ...   ...   \n",
       "2606  ../data/childes/VanHouten/Twos/teaching/parkt.cha  VanHouten   NaN   \n",
       "2607  ../data/childes/VanHouten/Twos/teaching/pricet...  VanHouten   NaN   \n",
       "2608  ../data/childes/VanHouten/Twos/teaching/raidt.cha  VanHouten   NaN   \n",
       "2609  ../data/childes/VanHouten/Twos/teaching/riott.cha  VanHouten   NaN   \n",
       "2610  ../data/childes/VanHouten/Twos/teaching/royalt...  VanHouten   NaN   \n",
       "\n",
       "     participants          name  age_d  age_m     sex           group  \\\n",
       "0      {CHI, MOT}  Target_Child    600   20.0  female              TD   \n",
       "1      {CHI, MOT}         Betty    600   20.0  female              TD   \n",
       "2      {CHI, MOT}         Chuck    600   20.0    male              TD   \n",
       "3      {CHI, MOT}          Doug    600   20.0    male              TD   \n",
       "4      {CHI, MOT}            Ed    600   20.0    male              TD   \n",
       "...           ...           ...    ...    ...     ...             ...   \n",
       "2606   {CHI, MOT}       Matthew    840   28.0    male       MOT_Older   \n",
       "2607   {CHI, MOT}         Peter    840   28.0    male  MOT_adolescent   \n",
       "2608   {CHI, MOT}         Tommy    840   28.0    male       MOT_older   \n",
       "2609   {CHI, MOT}        Robert    840   28.0    male  MOT_Adolescent   \n",
       "2610   {CHI, MOT}         Sarah    840   28.0  female  MOT_Adolescent   \n",
       "\n",
       "              ses      mot_edu  \\\n",
       "0              MC  unspecified   \n",
       "1              MC  unspecified   \n",
       "2              MC  unspecified   \n",
       "3              MC  unspecified   \n",
       "4              MC  unspecified   \n",
       "...           ...          ...   \n",
       "2606  unspecified  unspecified   \n",
       "2607  unspecified  unspecified   \n",
       "2608  unspecified  unspecified   \n",
       "2609  unspecified  unspecified   \n",
       "2610  unspecified  unspecified   \n",
       "\n",
       "                                              situation   activities  \\\n",
       "0                                           unspecified  unspecified   \n",
       "1                                           unspecified  unspecified   \n",
       "2                                           unspecified  unspecified   \n",
       "3                                           unspecified  unspecified   \n",
       "4                                           unspecified  unspecified   \n",
       "...                                                 ...          ...   \n",
       "2606  Teaching. Mother and Child sit on floor. First...  unspecified   \n",
       "2607  Teaching. Mother and Child sit on the floor in...  unspecified   \n",
       "2608  Teaching. Mother , Child and Father sit in liv...  unspecified   \n",
       "2609  Teaching. Mother and Child sit on the living r...  unspecified   \n",
       "2610  Teaching. Mother and Child sit on living room ...  unspecified   \n",
       "\n",
       "              study_type  \n",
       "0     cross, toyplay, TD  \n",
       "1     cross, toyplay, TD  \n",
       "2     cross, toyplay, TD  \n",
       "3     cross, toyplay, TD  \n",
       "4     cross, toyplay, TD  \n",
       "...                  ...  \n",
       "2606  cross, toyplay, TD  \n",
       "2607  cross, toyplay, TD  \n",
       "2608  cross, toyplay, TD  \n",
       "2609  cross, toyplay, TD  \n",
       "2610  cross, toyplay, TD  \n",
       "\n",
       "[2611 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3361cb-8567-41b4-9587-6c8532afb630",
   "metadata": {},
   "source": [
    "# Data cleaning and integration\n",
    "\n",
    "As mentioned in `data_curation.ipynb`, not all corpora use the same labels for some variables. For example, some corpora use school grade year to define mother's education (`mot_edu`), and some use level of education (e.g. 'college'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f54de0d-cd1c-4228-9fac-5b36415f4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'**', '10', '10 , GED', '102', '11', '11 , GED', '11+', '12', '12+', '13',\n",
      " '13+', '14', '15', '16', '6', '7', '8', '9', \"Associate's_Degree\", 'College',\n",
      " 'College_Doctoral', 'College_J.D.', \"College_Master's\", 'High_School_Diploma',\n",
      " 'MOT_1', 'MOT_2', 'MOT_3', 'Some_College', 'XX', 'almost 12', 'unspecified'}\n"
     ]
    }
   ],
   "source": [
    "mot_edu_labels = set(data_idx.mot_edu)\n",
    "cp.pprint(mot_edu_labels)  # Print compactly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8873969-e03f-4e1e-8bea-9eae40d49865",
   "metadata": {},
   "source": [
    "Besides `mot_edu`, other variables with different labels used in different corpora include:  \n",
    "- `group` (child's developmental group, e.g. typically developed)\n",
    "- `ses` (Child's SES (socioeconomic status; same as mother's))\n",
    "- `situation` Situation of recording (e.g. play session)\n",
    "- `activities` (Activities during recording, e.g. Toy play)\n",
    "- `study_type` type of study (e.g. longitudinal study)\n",
    "    \n",
    "I will change the labels for some of these variables, so that all corpora use the same set of labels.\n",
    "\n",
    "Below is a list of homepages for all the corpora appeared in the curated dataset. You can find the basic information about the corpus, such as variable and label definitions, on its homepage and in the linked publications. I will check these pages when the variable labels are ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca34969a-2c41-4e2d-bbab-fd22b5b63d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': 'https://childes.talkbank.org/access/Eng-NA/Bates.html',\n",
      " 'Bernstein': 'https://childes.talkbank.org/access/Eng-NA/Bernstein.html',\n",
      " 'Brown': 'https://childes.talkbank.org/access/Eng-NA/Brown.html',\n",
      " 'Clark': 'https://childes.talkbank.org/access/Eng-NA/Clark.html',\n",
      " 'Demetras2': 'https://childes.talkbank.org/access/Eng-NA/Demetras2.html',\n",
      " 'Gleason': 'https://childes.talkbank.org/access/Eng-NA/Gleason.html',\n",
      " 'HSLLD': 'https://childes.talkbank.org/access/Eng-NA/HSLLD.html',\n",
      " 'Hall': 'https://childes.talkbank.org/access/Eng-NA/Hall.html',\n",
      " 'Hicks': 'https://childes.talkbank.org/access/Eng-NA/Hicks.html',\n",
      " 'Nelson': 'https://childes.talkbank.org/access/Eng-NA/Nelson.html',\n",
      " 'NewmanRatner': 'https://childes.talkbank.org/access/Eng-NA/NewmanRatner.html',\n",
      " 'Post': 'https://childes.talkbank.org/access/Eng-NA/Post.html',\n",
      " 'VanHouten': 'https://childes.talkbank.org/access/Eng-NA/VanHouten.html'}\n"
     ]
    }
   ],
   "source": [
    "corpus_homepages = {}\n",
    "corpus_set = set(data_idx.corpus)\n",
    "\n",
    "for c in corpus_set:\n",
    "    url = \"https://childes.talkbank.org/access/Eng-NA/\" + c + \".html\"\n",
    "    corpus_homepages[c] = url\n",
    "\n",
    "cp.pprint(corpus_homepages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6bf77-5182-43a7-b6bf-4388bfcef4e4",
   "metadata": {},
   "source": [
    "### `mot_edu`\n",
    "\n",
    "I will start with the 'simplest' variable, `mot_edu`.\n",
    "First, let's find out which of the above labels each corpus uses for `mot_edu`. I will use a self-defined function, `get_labels()` (see header section of this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e9c964-dd4e-47f3-ae0f-460294291ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'unspecified'},\n",
      " 'Bernstein': {'unspecified'},\n",
      " 'Brown': {'unspecified'},\n",
      " 'Clark': {'unspecified'},\n",
      " 'Demetras2': {'unspecified'},\n",
      " 'Gleason': {'unspecified'},\n",
      " 'HSLLD': {'**', '10', '10 , GED', '102', '11', '11 , GED', '11+', '12', '12+',\n",
      "           '13', '13+', '14', '15', '16', '6', '7', '8', '9', 'XX', 'almost 12',\n",
      "           'unspecified'},\n",
      " 'Hall': {'unspecified'},\n",
      " 'Hicks': {'unspecified'},\n",
      " 'Nelson': {'unspecified'},\n",
      " 'NewmanRatner': {\"Associate's_Degree\", 'College', 'College_Doctoral',\n",
      "                  'College_J.D.', \"College_Master's\", 'High_School_Diploma',\n",
      "                  'Some_College', 'unspecified'},\n",
      " 'Post': {'unspecified'},\n",
      " 'VanHouten': {'MOT_1', 'unspecified', 'MOT_2', 'MOT_3'}}\n"
     ]
    }
   ],
   "source": [
    "cp.pprint(get_labels('mot_edu'))  # get_labels() is defined in header section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb5f00-5bbd-473b-ae78-c57ac1a5b52a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "--\n",
    "  \n",
    "As shown here, different classifications of education level are used in three corpora (HSLLD, NewmanRatner and VanHouten). HSLLD has a very detailed classification while VanHouten has only three classes. To merge all the labels across different corpora, I will use a less detailed classification without losing information needed for this project.\n",
    "\n",
    "The labels used in HSLLD correspond to the school grade year the mother achieved. In the U.S. educational system, 'GED' is equivalent to completing grade 12, so I will merge these two classes as one. The labels '13' and beyond correspond to some post-secondary education (e.g. vocational training).\n",
    "\n",
    "According to VanHouten's documentation, mother’s education is classified as MOT_1 (completed junior high), MOT_2 (completed high school) or MOT_3 (some post-secondary education).\n",
    "\n",
    "I will merge the current labels into the following labels according to their common definitions: \n",
    "\n",
    "- `JH-`, `HS-`, `HS`, `HS+` for:\n",
    "    - before completing junior high (before grade 9),\n",
    "    - before completing high school (before GED or grade 12),\n",
    "    - completed high school (GED or grade 12), and\n",
    "    - some post-secondary education (after high school).\n",
    "\n",
    "- `AD`, `UG-`, `UG` for:\n",
    "    - associate's degree,\n",
    "    - some undergraduate education, and\n",
    "    - bachelor's degree.\n",
    "\n",
    "- `MS`, `JD`, `DR` for:\n",
    "    - master's degree,\n",
    "    - juris doctor degree, and\n",
    "    - doctoral degree.\n",
    "    \n",
    "I will map the current `mot_edu` labels to the above new labels with a `dictionary` and update `data_idx` with the new labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06bcf1c-bb74-4995-af05-6b1d33bbb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'unspecified'},\n",
      " 'Bernstein': {'unspecified'},\n",
      " 'Brown': {'unspecified'},\n",
      " 'Clark': {'unspecified'},\n",
      " 'Demetras2': {'unspecified'},\n",
      " 'Gleason': {'unspecified'},\n",
      " 'HSLLD': {'HS', 'unspecified', 'HS-', 'JH-', 'HS+'},\n",
      " 'Hall': {'unspecified'},\n",
      " 'Hicks': {'unspecified'},\n",
      " 'Nelson': {'unspecified'},\n",
      " 'NewmanRatner': {'UG', 'HS', 'unspecified', 'DR', 'UG-', 'AD', 'MS', 'JD'},\n",
      " 'Post': {'unspecified'},\n",
      " 'VanHouten': {'HS', 'unspecified', 'HS+', 'HS-'}}\n"
     ]
    }
   ],
   "source": [
    "# Function to update 'mot_edu'\n",
    "def update_mot_edu(data):\n",
    "    label = data\n",
    "    #' mot_edu' label mapping\n",
    "    EDU_DICT = {\n",
    "              'JH-':['6','7','8'],\n",
    "              'HS-':['9','10','11','11+','almost 12','MOT_1'],\n",
    "              'HS':['10 , GED','11 , GED','12','12+',\n",
    "                    'High_School_Diploma','MOT_2'],\n",
    "              'HS+':['13','13+','14','15','16','MOT_3'],\n",
    "              'AD':[\"Associate's_Degree\"],\n",
    "              'UG-':['Some_College'],\n",
    "              'UG':['College'], \n",
    "              'MS':[\"College_Master's\"],\n",
    "              'JD':['College_J.D.'],    \n",
    "              'DR':['College_Doctoral'],\n",
    "              'unspecified':['**','102','XX','unspecified']\n",
    "               }\n",
    "    \n",
    "    for key in EDU_DICT:\n",
    "        if data in EDU_DICT[key]:\n",
    "            label = key\n",
    "    return label\n",
    "\n",
    "# Update 'mot_edu'\n",
    "data_idx.mot_edu = data_idx.mot_edu.map(update_mot_edu)\n",
    "\n",
    "# Check if update was successful\n",
    "cp.pprint(get_labels('mot_edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa80639-4ba2-4d47-901a-e7f48983074c",
   "metadata": {},
   "source": [
    "--\n",
    "\n",
    "All labels for `mot_edu` were updated sucessfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fb19e-4e70-4d80-9596-2cced3f53580",
   "metadata": {},
   "source": [
    "### `group`\n",
    "\n",
    "Below are the labels used in different corpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f766a891-419a-4f5e-b1e5-eec689bbcebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'TD'},\n",
      " 'Bernstein': {'TD', 'unspecified'},\n",
      " 'Brown': {'TD', 'unspecified'},\n",
      " 'Clark': {'TD'},\n",
      " 'Demetras2': {'TD', 'unspecified'},\n",
      " 'Gleason': {'TD', 'unspecified', 'typical', 'normal'},\n",
      " 'HSLLD': {'unspecified'},\n",
      " 'Hall': {'TD', 'unspecified', 'White,UC'},\n",
      " 'Hicks': {'unspecified'},\n",
      " 'Nelson': {'unspecified'},\n",
      " 'NewmanRatner': {'TD'},\n",
      " 'Post': {'TD'},\n",
      " 'VanHouten': {'MOT_Adolescent', 'MOT_Adolescent_', 'MOT_Older', 'MOT_Older_',\n",
      "               'MOT_adolescent', 'MOT_older', 'TD', 'unspecified'}}\n"
     ]
    }
   ],
   "source": [
    "cp.pprint(get_labels('group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb59a9-7ca0-434f-8ad2-d76dca08c400",
   "metadata": {},
   "source": [
    "--\n",
    "\n",
    "As shown above, the `group` information of each file is not properly speficied in every corpus: \n",
    "- According the documentations of the corpora, all children in the dataset should be typically developed (`TD` in `group`). However, not all corpora put this information in the `group` field in the header of each file. Therefore, I will change the `unspecified` label to `TD`.\n",
    "- in the Gleason corpus, labels `normal` and `typical` are used in additon to `TD`. I will change all labels to `TD`.\n",
    "- In the Hall corpus, the labels for `group` and `ses` were switched in some files (e.g. `White,UC` should be a label for `ses`). I will switch them first and change all `group` labels to `TD`.\n",
    "- In the VanHouten corpus, all children are `TD`, but it also contains data from adolescent mothers which I will not use for this project. I will first remove these files and change all labels to `TD`.\n",
    "\n",
    "Let's take a quick look at the Hall corpus first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9564ce9b-60ed-4127-89c2-2253f2847d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>ses</th>\n",
       "      <th>study_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>Black,WC</td>\n",
       "      <td>cross, everyday, AAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>White,UC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, everyday, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>White,UC</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>cross, everyday, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            group          ses            study_type\n",
       "1471  unspecified     Black,WC  cross, everyday, AAE\n",
       "1472  unspecified     Black,WC  cross, everyday, AAE\n",
       "1473  unspecified     Black,WC  cross, everyday, AAE\n",
       "1474  unspecified     Black,WC  cross, everyday, AAE\n",
       "1475  unspecified     Black,WC  cross, everyday, AAE\n",
       "1476  unspecified     Black,WC  cross, everyday, AAE\n",
       "1477  unspecified     Black,WC  cross, everyday, AAE\n",
       "1478  unspecified     Black,WC  cross, everyday, AAE\n",
       "1479  unspecified     Black,WC  cross, everyday, AAE\n",
       "1480  unspecified     Black,WC  cross, everyday, AAE\n",
       "1482     White,UC  unspecified   cross, everyday, TD\n",
       "1485     White,UC  unspecified   cross, everyday, TD\n",
       "1492  unspecified  unspecified           unspecified"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['TD', 'typical', 'normal']\n",
    "data_idx[['group','ses','study_type']][(data_idx.corpus=='Hall') & \n",
    "                                       ~(data_idx.group.isin(labels))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922168c-b4be-4873-806a-70080c8f02cf",
   "metadata": {},
   "source": [
    "As shown above in row 1482 and 1485, the label `White,UC` (i.e. upper class white) is actually a label for `ses`. I will copy the labels to `ses` of the corresponding rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b173992f-2ca7-477f-add2-47eaaefbe181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>ses</th>\n",
       "      <th>study_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>White,UC</td>\n",
       "      <td>White,UC</td>\n",
       "      <td>cross, everyday, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>White,UC</td>\n",
       "      <td>White,UC</td>\n",
       "      <td>cross, everyday, TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group       ses           study_type\n",
       "1482  White,UC  White,UC  cross, everyday, TD\n",
       "1485  White,UC  White,UC  cross, everyday, TD"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_idx.loc[data_idx.group=='White,UC','ses'] = 'White,UC'\n",
    "\n",
    "# Check if ses labels were updated\n",
    "data_idx.loc[[1482,1485],['group','ses','study_type']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8276bee-3656-401c-a8b7-b13ae1de181b",
   "metadata": {},
   "source": [
    "Note that the `group` labels are still `White,UC`, but I will change them to `TD` together with other corpora later.  \n",
    "Next, I will drop the data collected from adolescent mothers in the VanHouten corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfd2c1d-7e4d-4fe0-a8c2-a4eb5fc2e288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'TD'},\n",
      " 'Bernstein': {'TD', 'unspecified'},\n",
      " 'Brown': {'TD', 'unspecified'},\n",
      " 'Clark': {'TD'},\n",
      " 'Demetras2': {'TD', 'unspecified'},\n",
      " 'Gleason': {'TD', 'unspecified', 'typical', 'normal'},\n",
      " 'HSLLD': {'unspecified'},\n",
      " 'Hall': {'TD', 'unspecified', 'White,UC'},\n",
      " 'Hicks': {'unspecified'},\n",
      " 'Nelson': {'unspecified'},\n",
      " 'NewmanRatner': {'TD'},\n",
      " 'Post': {'TD'},\n",
      " 'VanHouten': {'MOT_Older', 'unspecified', 'TD', 'MOT_older', 'MOT_Older_'}}\n"
     ]
    }
   ],
   "source": [
    "drop_labels = ['MOT_Adolescent', 'MOT_Adolescent_', 'MOT_adolescent']\n",
    "data_idx.drop(data_idx[data_idx.group.isin(drop_labels)].index, inplace=True)\n",
    "\n",
    "# Check current labels\n",
    "cp.pprint(get_labels('group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93f8d5-b84a-4c31-b4dd-894cb671ff70",
   "metadata": {},
   "source": [
    "--\n",
    "\n",
    "Finally, we are ready to change all the labels to `TD`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372fdcb7-cad6-47d0-9a0b-50249057d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'TD'},\n",
      " 'Bernstein': {'TD'},\n",
      " 'Brown': {'TD'},\n",
      " 'Clark': {'TD'},\n",
      " 'Demetras2': {'TD'},\n",
      " 'Gleason': {'TD'},\n",
      " 'HSLLD': {'TD'},\n",
      " 'Hall': {'TD'},\n",
      " 'Hicks': {'TD'},\n",
      " 'Nelson': {'TD'},\n",
      " 'NewmanRatner': {'TD'},\n",
      " 'Post': {'TD'},\n",
      " 'VanHouten': {'TD'}}\n"
     ]
    }
   ],
   "source": [
    "# Change all 'group' label to \n",
    "data_idx['group'] = 'TD'\n",
    "\n",
    "# Check updated labels\n",
    "cp.pprint(get_labels('group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd139948-239b-4e5c-836f-11f064d57541",
   "metadata": {},
   "source": [
    "--\n",
    "\n",
    "### `ses`\n",
    "\n",
    "Below are the labels for `ses`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7dfad76-06de-41ba-9cdf-012c21a5900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'MC'},\n",
      " 'Bernstein': {'unspecified', 'MC'},\n",
      " 'Brown': {'unspecified', 'MC'},\n",
      " 'Clark': {'UC'},\n",
      " 'Demetras2': {'unspecified', 'WC'},\n",
      " 'Gleason': {'unspecified', 'MC'},\n",
      " 'HSLLD': {'unspecified'},\n",
      " 'Hall': {'unspecified', 'Black,UC', 'White,WC', 'Black,WC', 'White,UC'},\n",
      " 'Hicks': {'LI', 'unspecified'},\n",
      " 'Nelson': {'unspecified', 'MC'},\n",
      " 'NewmanRatner': {'unspecified'},\n",
      " 'Post': {'WC'},\n",
      " 'VanHouten': {'unspecified'}}\n"
     ]
    }
   ],
   "source": [
    "cp.pprint(get_labels('ses'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05a6af-c78c-4e78-b9e3-a90d48dd55a1",
   "metadata": {},
   "source": [
    "--\n",
    "\n",
    "In these corpora, `WC`, `MC`, `UC` and `LI` mean 'working class', 'middle class', 'upper class' and 'low income' respectively. Different labels are used in different corpora:\n",
    "- In the Hall corpus, each class of `WC` and `UC` is subdivided into two racial groups, `Black` and `White`. Since the primary goal of this project is to investigate the effects of SES and mother's education on vocabulary development, effects from other factors such as race will not be studied. I will merge the labels for different racial groups but same SES class together to get a larger sample size for each class. Although race may play an important role in children's language development, I hope that the balanced distribution of samples from different racial groups in the Hall Corpus will minimize the effects of race on my analysis.\n",
    "- In the Hicks corpus, `LI` ('low income') is used instead of common SES class such as `WC`. Since the majority of low-come families presumably belong to the working class, I will change the label `LI` to `WC`. - Besides, the children in the subdirectories '1st', '2nd', and '5th' were considered coming from `MC` families. The children in the subdirectory 'del' were from lower class (presumably `WC`) families. I will assigned the missed labels accordingly.\n",
    "- It is stated on the homepage of the Bernstein corpus that \"the mothers were all college-educated women, who were native-born Americans with white-collar husband\". Since all families in the study have similar background and some of the files were labeled `MC`, it is very likely that other files should also be labeled `MC`.\n",
    "- The Brown corpus contains data from three children: Adam (`MC`), Sarah (`WC`) and Eve (`unspecified`). I will assigned the missed labels accordingly.\n",
    "- All children in the Demetras2 corpus were from `WC` families.\n",
    "- All children in the Gleason corpus were from `MC` families.\n",
    "- All children in the HSLLD corpus were from low-income families. I will use the label `WC`.\n",
    "- There is only one child in the Nelson corpus and she came from a `MC` family.\n",
    "\n",
    "There are two corpora where no SES class information could be found:\n",
    "- NewmanRatner corpus\n",
    "- VanHouten corpus: Only Hollingshead index (a measurement of SES) is provided.\n",
    "\n",
    "Let's begin cleaning up the `ses` labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "082438a5-f188-4b85-9f28-ba7e279533bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bates': {'MC'},\n",
      " 'Bernstein': {'MC'},\n",
      " 'Brown': {'unspecified', 'MC', 'WC'},\n",
      " 'Clark': {'UC'},\n",
      " 'Demetras2': {'WC'},\n",
      " 'Gleason': {'MC'},\n",
      " 'HSLLD': {'WC'},\n",
      " 'Hall': {'unspecified', 'UC', 'WC'},\n",
      " 'Hicks': {'unspecified', 'MC', 'WC'},\n",
      " 'Nelson': {'MC'},\n",
      " 'NewmanRatner': {'unspecified'},\n",
      " 'Post': {'WC'},\n",
      " 'VanHouten': {'unspecified'}}\n"
     ]
    }
   ],
   "source": [
    "# Function to merge 'ses' labels\n",
    "def merge_ses(data):\n",
    "    label = data\n",
    "    # 'ses' label mapping\n",
    "    SES_DICT = {'WC':['WC', 'Black,WC', 'White,WC', 'LI'],\n",
    "                'UC':['UC', 'Black,UC', 'White,UC']}\n",
    "    for key in SES_DICT:\n",
    "        if data in SES_DICT[key]:\n",
    "            label = key\n",
    "    return label\n",
    "\n",
    "# merge 'ses' labels in Hall and Hicks corpus: \n",
    "data_idx.ses = data_idx.ses.map(merge_ses)\n",
    "\n",
    "# Update labels in Hicks corpus\n",
    "for folder in ['1st','2nd','5th']:\n",
    "    data_idx.loc[((data_idx.corpus=='Hicks') & \n",
    "                  (data_idx.file_path.map(lambda x: folder in x))),'ses'] = 'MC'\n",
    "data_idx.loc[((data_idx.corpus=='Hicks') & \n",
    "              (data_idx.file_path.map(lambda x: 'del' in x))),'ses'] = 'WC'\n",
    "\n",
    "# Update labels in Brown corpus\n",
    "data_idx.loc[((data_idx.corpus=='Brown')& (data_idx.name=='Adam')),'ses'] = 'MC'\n",
    "data_idx.loc[((data_idx.corpus=='Brown')&(data_idx.name=='Sarah')),'ses'] = 'WC'\n",
    "\n",
    "# Update labels in other corpora\n",
    "data_idx.loc[data_idx.corpus=='Bernstein','ses'] = 'MC'\n",
    "data_idx.loc[data_idx.corpus=='Demetras2','ses'] = 'WC'\n",
    "data_idx.loc[data_idx.corpus=='Gleason','ses'] = 'MC'\n",
    "data_idx.loc[data_idx.corpus=='HSLLD','ses'] = 'WC'\n",
    "data_idx.loc[data_idx.corpus=='Nelson','ses'] = 'MC'\n",
    "\n",
    "# # Check updated labels\n",
    "cp.pprint(get_labels('ses'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700964c-0cb6-40b1-ba2c-27bdf8a0ff4b",
   "metadata": {},
   "source": [
    "### `situation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e013699-6363-41b0-91ec-065022613828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unspecified', 1299),\n",
       " ('home', 658),\n",
       " ('visit', 561),\n",
       " ('the', 439),\n",
       " ('and', 423),\n",
       " ('on', 397),\n",
       " ('in', 339),\n",
       " (',', 315),\n",
       " ('chi', 277),\n",
       " ('mot', 242),\n",
       " ('with', 240),\n",
       " ('is', 196),\n",
       " ('place', 175),\n",
       " ('to', 164),\n",
       " ('living', 158),\n",
       " ('1', 144),\n",
       " ('3', 143),\n",
       " ('mother', 142),\n",
       " ('room', 140),\n",
       " ('kitchen', 139),\n",
       " ('took', 137),\n",
       " ('sitting', 136),\n",
       " ('of', 135),\n",
       " ('at', 126),\n",
       " ('floor', 123),\n",
       " ('sarah', 122),\n",
       " ('a', 121),\n",
       " ('first', 120),\n",
       " ('session', 111),\n",
       " ('visit;', 110),\n",
       " ('second', 101),\n",
       " ('child', 101),\n",
       " ('table', 93),\n",
       " ('are', 90),\n",
       " ('play', 82),\n",
       " ('couch', 79),\n",
       " ('toys', 76),\n",
       " ('playing', 74),\n",
       " ('her', 72),\n",
       " ('2', 71),\n",
       " ('sat', 66),\n",
       " ('next', 65),\n",
       " ('1;', 60),\n",
       " ('room;', 56),\n",
       " ('book', 49),\n",
       " ('playroom', 48),\n",
       " ('3;', 48),\n",
       " ('as', 47),\n",
       " ('toy', 47),\n",
       " ('(lab)', 46),\n",
       " ('chair', 45),\n",
       " ('freeplay', 45),\n",
       " ('before', 44),\n",
       " ('sits', 44),\n",
       " ('sit', 44),\n",
       " ('tape', 43),\n",
       " ('time', 43),\n",
       " ('meal', 43),\n",
       " ('takes', 41),\n",
       " (\"mot's\", 40),\n",
       " ('lap', 39),\n",
       " ('afternoon', 38),\n",
       " ('reading', 36),\n",
       " ('bed', 36),\n",
       " ('2;', 36),\n",
       " ('from', 35),\n",
       " ('this', 34),\n",
       " ('has', 34),\n",
       " ('other', 32),\n",
       " ('then', 32),\n",
       " ('side', 32),\n",
       " ('by', 31),\n",
       " ('for', 30),\n",
       " ('elicited', 30),\n",
       " ('was', 29),\n",
       " ('each', 29),\n",
       " ('report', 29),\n",
       " ('late', 28),\n",
       " ('dinner', 28),\n",
       " ('mother/child', 27),\n",
       " ('she', 27),\n",
       " ('not', 26),\n",
       " ('early', 26),\n",
       " ('teaches', 26),\n",
       " ('occurred', 25),\n",
       " ('during', 24),\n",
       " ('exp', 24),\n",
       " ('third', 23),\n",
       " ('father', 22),\n",
       " ('bro', 22),\n",
       " ('intelligible.', 22),\n",
       " ('out', 21),\n",
       " ('begins', 21),\n",
       " (\"sarah's\", 21),\n",
       " ('just', 21),\n",
       " ('conversation', 21),\n",
       " ('o', 21),\n",
       " ('while', 20),\n",
       " ('night', 20),\n",
       " ('kitchen;', 20),\n",
       " ('fairly', 20),\n",
       " ('recording', 19),\n",
       " ('up', 19),\n",
       " ('sofa', 19),\n",
       " ('present', 18),\n",
       " ('very', 18),\n",
       " ('interview', 17),\n",
       " ('adam', 17),\n",
       " ('two', 17),\n",
       " ('his', 17),\n",
       " ('seated', 17),\n",
       " ('lunch.', 17),\n",
       " ('into', 16),\n",
       " ('eating', 16),\n",
       " ('together', 16),\n",
       " ('floor.', 16),\n",
       " ('speech', 15),\n",
       " ('standing', 15),\n",
       " ('string', 15),\n",
       " ('maternal', 14),\n",
       " ('nap', 14),\n",
       " ('table.', 14),\n",
       " ('white', 14),\n",
       " ('couch;', 14),\n",
       " (\"child's\", 14),\n",
       " ('teaching.', 14),\n",
       " ('them', 13),\n",
       " ('all', 13),\n",
       " ('courtney', 13),\n",
       " ('morning', 13),\n",
       " ('sis', 13),\n",
       " ('they', 13),\n",
       " ('sort', 13),\n",
       " ('black', 13),\n",
       " ('ursula', 12),\n",
       " ('were', 12),\n",
       " ('but', 12),\n",
       " ('had', 12),\n",
       " ('both', 12),\n",
       " ('d', 12),\n",
       " ('toys.', 12),\n",
       " ('floor;', 12),\n",
       " ('teaching', 12),\n",
       " ('baby', 11),\n",
       " ('paul', 11),\n",
       " ('made', 11),\n",
       " ('utterances', 11),\n",
       " ('children', 11),\n",
       " ('him', 11),\n",
       " ('day', 11),\n",
       " ('4', 11),\n",
       " ('evening', 11),\n",
       " ('which', 10),\n",
       " ('gloria', 10),\n",
       " ('an', 10),\n",
       " ('box', 10),\n",
       " ('front', 10),\n",
       " ('table;', 10),\n",
       " ('dining', 10),\n",
       " ('story', 10),\n",
       " ('freeplay.', 10),\n",
       " (\"adam's\", 9),\n",
       " ('it', 9),\n",
       " ('last', 9),\n",
       " ('still', 9),\n",
       " ('family', 9),\n",
       " ('there', 9),\n",
       " ('dog', 9),\n",
       " ('starts', 9),\n",
       " ('small', 9),\n",
       " ('m', 9),\n",
       " ('rug', 9),\n",
       " ('experimenter', 9),\n",
       " ('provided', 9),\n",
       " ('about', 8),\n",
       " ('one', 8),\n",
       " ('brother', 8),\n",
       " ('near', 8),\n",
       " ('only', 8),\n",
       " ('when', 8),\n",
       " ('down', 8),\n",
       " ('noise', 8),\n",
       " (\"mother's\", 8),\n",
       " ('beside', 8),\n",
       " ('that', 8),\n",
       " ('after', 8),\n",
       " ('mostly', 8),\n",
       " ('gail', 8),\n",
       " ('david', 8),\n",
       " ('together;', 8),\n",
       " ('lap;', 8),\n",
       " ('does', 8),\n",
       " ('beads', 8),\n",
       " ('most', 7),\n",
       " ('another', 7),\n",
       " ('room.', 7),\n",
       " ('eve', 7),\n",
       " ('beads.', 7),\n",
       " ('been', 7),\n",
       " ('or', 7),\n",
       " ('lunch', 7),\n",
       " ('read', 7),\n",
       " ('quite', 7),\n",
       " ('around', 7),\n",
       " ('runs', 7),\n",
       " ('off', 7),\n",
       " ('dad', 7),\n",
       " ('reads', 7),\n",
       " (';', 7),\n",
       " ('coffee', 7),\n",
       " ('tc', 7),\n",
       " ('magnets', 7),\n",
       " ('buttons', 7),\n",
       " ('following', 6),\n",
       " ('kitchen.', 6),\n",
       " ('throughout', 6),\n",
       " ('be', 6),\n",
       " ('few', 6),\n",
       " ('am', 6),\n",
       " ('have', 6),\n",
       " ('some', 6),\n",
       " ('present.', 6),\n",
       " ('he', 6),\n",
       " ('because', 6),\n",
       " ('ann_marie', 6),\n",
       " ('talk', 6),\n",
       " ('talking', 6),\n",
       " ('paper', 6),\n",
       " ('bag', 6),\n",
       " ('melissa', 6),\n",
       " ('background', 6),\n",
       " ('s', 6),\n",
       " ('between', 6),\n",
       " (\"chi's\", 6),\n",
       " ('carpet', 6),\n",
       " ('scary', 6),\n",
       " ('shoelace.', 6),\n",
       " ('buttons.', 6),\n",
       " ('holding', 5),\n",
       " ('part', 5),\n",
       " ('mrs', 5),\n",
       " ('summer', 5),\n",
       " ('hour', 5),\n",
       " ('than', 5),\n",
       " ('sleeping', 5),\n",
       " ('week', 5),\n",
       " ('who', 5),\n",
       " ('arrived', 5),\n",
       " ('wooden', 5),\n",
       " ('more', 5),\n",
       " ('work', 5),\n",
       " ('today', 5),\n",
       " ('over', 5),\n",
       " ('books', 5),\n",
       " ('house', 5),\n",
       " ('looking', 5),\n",
       " ('turned', 5),\n",
       " ('voice', 5),\n",
       " ('back', 5),\n",
       " ('transcribed.', 5),\n",
       " ('set', 5),\n",
       " ('minutes', 5),\n",
       " ('returned', 5),\n",
       " ('notes', 5),\n",
       " ('kent', 5),\n",
       " ('left', 5),\n",
       " ('warm', 5),\n",
       " ('looks', 5),\n",
       " ('plays', 5),\n",
       " ('little', 5),\n",
       " ('phone', 5),\n",
       " ('spread', 5),\n",
       " ('separate', 5),\n",
       " ('leaning', 5),\n",
       " ('porch;', 5),\n",
       " ('bedroom;', 5),\n",
       " ('inv', 5),\n",
       " ('played', 5),\n",
       " ('gets', 5),\n",
       " ('afternoon;', 5),\n",
       " ('jumps', 5),\n",
       " ('holds', 5),\n",
       " ('alone', 4),\n",
       " ('water', 4),\n",
       " ('note:', 4),\n",
       " ('hot', 4),\n",
       " ('recording.', 4),\n",
       " ('tape.', 4),\n",
       " ('seems', 4),\n",
       " ('usual', 4),\n",
       " ('hand', 4),\n",
       " ('three', 4),\n",
       " ('so', 4),\n",
       " ('although', 4),\n",
       " ('makes', 4),\n",
       " ('mike', 4),\n",
       " ('joins', 4),\n",
       " ('friend', 4),\n",
       " ('puts', 4),\n",
       " ('started', 4),\n",
       " ('getting', 4),\n",
       " ('much', 4),\n",
       " ('entire', 4),\n",
       " ('comes', 4),\n",
       " ('piece', 4),\n",
       " ('waiting', 4),\n",
       " ('recorder', 4),\n",
       " ('high', 4),\n",
       " ('plastic', 4),\n",
       " ('later', 4),\n",
       " ('talks', 4),\n",
       " ('cutting', 4),\n",
       " ('puzzle', 4),\n",
       " ('start', 4),\n",
       " ('working', 4),\n",
       " ('blocks', 4),\n",
       " ('mom', 4),\n",
       " ('somewhat', 4),\n",
       " ('chairs', 4),\n",
       " ('television', 4),\n",
       " ('easy', 4),\n",
       " ('jak', 4),\n",
       " ('br', 4),\n",
       " ('er', 4),\n",
       " ('tp', 4),\n",
       " ('livingroom', 4),\n",
       " ('their', 4),\n",
       " ('facing', 4),\n",
       " ('mealtime', 4),\n",
       " ('head', 4),\n",
       " ('being', 4),\n",
       " ('tells', 4),\n",
       " ('living+room', 4),\n",
       " ('clock', 4),\n",
       " ('one-word', 4),\n",
       " ('comprehensible.', 4),\n",
       " ('tries', 4),\n",
       " ('unintelligible.', 4),\n",
       " ('piles.', 4),\n",
       " ('boxes.', 4),\n",
       " ('new', 3),\n",
       " ('session.', 3),\n",
       " ('activity', 3),\n",
       " ('time.', 3),\n",
       " ('will', 3),\n",
       " ('smith', 3),\n",
       " ('cold', 3),\n",
       " ('less', 3),\n",
       " ('puppets', 3),\n",
       " ('diandra', 3),\n",
       " ('asleep', 3),\n",
       " ('large', 3),\n",
       " ('says', 3),\n",
       " ('told', 3),\n",
       " ('visiting.', 3),\n",
       " ('drinking', 3),\n",
       " ('roger', 3),\n",
       " ('brown', 3),\n",
       " ('stands', 3),\n",
       " ('today.', 3),\n",
       " ('gotten', 3),\n",
       " ('occasionally', 3),\n",
       " ('wear', 3),\n",
       " ('since', 3),\n",
       " ('year', 3),\n",
       " ('picked', 3),\n",
       " ('well', 3),\n",
       " ('until', 3),\n",
       " ('eat', 3),\n",
       " ('transcription', 3),\n",
       " ('past', 3),\n",
       " ('would', 3),\n",
       " ('situation', 3),\n",
       " ('car', 3),\n",
       " ('door', 3),\n",
       " ('edge', 3),\n",
       " ('given', 3),\n",
       " ('same', 3),\n",
       " (\"barnes's\", 3),\n",
       " ('run', 3),\n",
       " ('am.', 3),\n",
       " ('awakened', 3),\n",
       " ('enters', 3),\n",
       " ('works', 3),\n",
       " ('bunny', 3),\n",
       " ('big', 3),\n",
       " ('face', 3),\n",
       " ('half', 3),\n",
       " ('brought', 3),\n",
       " ('arm', 3),\n",
       " ('microphone', 3),\n",
       " ('c', 3),\n",
       " ('own', 3),\n",
       " ('break', 3),\n",
       " ('walking', 3),\n",
       " ('tower', 3),\n",
       " ('7', 3),\n",
       " ('living+room.', 3),\n",
       " ('surrounded', 3),\n",
       " ('elliot', 3),\n",
       " ('what', 3),\n",
       " ('lego', 3),\n",
       " ('pm', 3),\n",
       " ('look', 3),\n",
       " ('cal', 3),\n",
       " ('zan', 3),\n",
       " ('mid', 3),\n",
       " ('her;', 3),\n",
       " ('fournier', 3),\n",
       " ('11:30', 3),\n",
       " ('chair.', 3),\n",
       " ('nearby', 3),\n",
       " ('sister', 3),\n",
       " ('10:30', 3),\n",
       " ('alternately', 3),\n",
       " ('preparing', 3),\n",
       " ('watching', 3),\n",
       " ('through', 3),\n",
       " ('pages', 3),\n",
       " ('say', 3),\n",
       " (\"exp's\", 3),\n",
       " ('eats', 3),\n",
       " ('gilmartin', 3),\n",
       " ('truck', 3),\n",
       " ('speaks', 3),\n",
       " ('shapes', 3),\n",
       " ('blocks.', 3),\n",
       " ('virtually', 3),\n",
       " ('interaction.', 3),\n",
       " ('walks', 3),\n",
       " ('camera.', 3),\n",
       " ('clear.', 3),\n",
       " ('younger', 3),\n",
       " ('includes', 2),\n",
       " ('brother.', 2),\n",
       " ('cecile', 2),\n",
       " (\"smith's\", 2),\n",
       " ('niece', 2),\n",
       " ('too', 2),\n",
       " ('extremely', 2),\n",
       " ('no', 2),\n",
       " ('transcribed', 2),\n",
       " ('written', 2),\n",
       " ('tired', 2),\n",
       " ('word', 2),\n",
       " ('beginning', 2),\n",
       " ('recorded', 2),\n",
       " ('came', 2),\n",
       " ('birthday', 2),\n",
       " ('several', 2),\n",
       " ('used', 2),\n",
       " ('staying', 2),\n",
       " ('mrs.', 2),\n",
       " ('brings', 2),\n",
       " ('began.', 2),\n",
       " ('often', 2),\n",
       " ('began', 2),\n",
       " ('having', 2),\n",
       " ('sister.', 2),\n",
       " ('5', 2),\n",
       " ('gone', 2),\n",
       " ('cooper', 2),\n",
       " ('rather', 2),\n",
       " ('investigators', 2),\n",
       " ('aid', 2),\n",
       " ('john', 2),\n",
       " ('crowley', 2),\n",
       " ('leaves', 2),\n",
       " ('window', 2),\n",
       " ('evidently', 2),\n",
       " ('her.', 2),\n",
       " ('making', 2),\n",
       " ('bowl', 2),\n",
       " ('points', 2),\n",
       " ('potato+chips', 2),\n",
       " ('milk', 2),\n",
       " (\"gloria's\", 2),\n",
       " (\"dri's\", 2),\n",
       " ('grandmother', 2),\n",
       " ('also', 2),\n",
       " ('nana', 2),\n",
       " (\"father's\", 2),\n",
       " ('old', 2),\n",
       " ('cousin', 2),\n",
       " ('visiting', 2),\n",
       " ('wearing', 2),\n",
       " ('jo_ann', 2),\n",
       " ('microphones', 2),\n",
       " ('silent', 2),\n",
       " ('hair', 2),\n",
       " ('finishes', 2),\n",
       " ('discuss', 2),\n",
       " ('reports', 2),\n",
       " ('stay', 2),\n",
       " ('level', 2),\n",
       " ('end', 2),\n",
       " ('sleepy', 2),\n",
       " ('active', 2),\n",
       " ('see', 2),\n",
       " ('intervals', 2),\n",
       " ('order', 2),\n",
       " ('pajamas', 2),\n",
       " ('gives', 2),\n",
       " ('find', 2),\n",
       " ('regular', 2),\n",
       " ('arrives', 2),\n",
       " ('courtney.', 2),\n",
       " ('almost', 2),\n",
       " ('number', 2),\n",
       " ('6', 2),\n",
       " ('previous', 2),\n",
       " ('vacation', 2),\n",
       " ('follows', 2),\n",
       " ('fifteen', 2),\n",
       " ('minute', 2),\n",
       " ('intermission', 2),\n",
       " ('without', 2),\n",
       " ('animals', 2),\n",
       " ('shortly', 2),\n",
       " ('emptied', 2),\n",
       " ('bed+room', 2),\n",
       " ('entered', 2),\n",
       " ('knees', 2),\n",
       " ('finished', 2),\n",
       " ('millisandy', 2),\n",
       " ('chantilly', 2),\n",
       " ('loudly', 2),\n",
       " ('talk.', 2),\n",
       " ('slate.', 2),\n",
       " ('candy', 2),\n",
       " ('onto', 2),\n",
       " ('school.', 2),\n",
       " ('tv', 2),\n",
       " ('clothes', 2),\n",
       " ('nursery', 2),\n",
       " ('school', 2),\n",
       " (\"gail's\", 2),\n",
       " ('come', 2),\n",
       " ('fight', 2),\n",
       " ('shape', 2),\n",
       " ('noises', 2),\n",
       " ('plotkin', 2),\n",
       " ('bellugi', 2),\n",
       " ('tape+recorder', 2),\n",
       " (\"s's\", 2),\n",
       " ('taping', 2),\n",
       " ('oliver', 2),\n",
       " ('8', 2),\n",
       " ('various', 2),\n",
       " ('10', 2),\n",
       " ('11', 2),\n",
       " ('12', 2),\n",
       " ('including', 2),\n",
       " ('cars', 2),\n",
       " ('portions', 2),\n",
       " (\"o's\", 2),\n",
       " ('causing', 2),\n",
       " ('distortions', 2),\n",
       " ('echoing', 2),\n",
       " ('effects.', 2),\n",
       " ('chalkboard', 2),\n",
       " ('recovering', 2),\n",
       " ('slightly', 2),\n",
       " ('hyponasal.', 2),\n",
       " ('like', 2),\n",
       " ('someone', 2),\n",
       " ('go', 2),\n",
       " ('fat', 2),\n",
       " ('fem', 2),\n",
       " ('lyn', 2),\n",
       " ('deb', 2),\n",
       " ('hungry', 2),\n",
       " ('caterpillar', 2),\n",
       " ('kneeling', 2),\n",
       " ('p.m.)', 2),\n",
       " ('older', 2),\n",
       " ('visit:', 2),\n",
       " ('readings', 2),\n",
       " ('either', 2),\n",
       " ('gma', 2),\n",
       " ('play;', 2),\n",
       " ('wil', 2),\n",
       " ('afternoon.', 2),\n",
       " ('dnl', 2),\n",
       " ('chair;', 2),\n",
       " (\"ste's\", 2),\n",
       " ('ste', 2),\n",
       " ('laying', 2),\n",
       " ('experimenters', 2),\n",
       " ('mot.', 2),\n",
       " ('-', 2),\n",
       " ('walked', 2),\n",
       " ('away', 2),\n",
       " ('moved', 2),\n",
       " ('sofa;', 2),\n",
       " ('bro1', 2),\n",
       " ('breakfast', 2),\n",
       " ('1:', 2),\n",
       " ('carpeted', 2),\n",
       " ('ball', 2),\n",
       " ('hallway', 2),\n",
       " ('toys;', 2),\n",
       " ('pointing', 2),\n",
       " ('off;', 2),\n",
       " ('dumped', 2),\n",
       " ('mid-afternoon;', 2),\n",
       " ('peter', 2),\n",
       " ('hear', 2),\n",
       " ('outside', 2),\n",
       " ('mid-afternoon', 2),\n",
       " ('bedroom', 2),\n",
       " ('twins', 2),\n",
       " ('target', 2),\n",
       " ('context', 2),\n",
       " ('wants', 2),\n",
       " ('shoulder', 2),\n",
       " ('quietly!', 2),\n",
       " ('story.', 2),\n",
       " ('street', 2),\n",
       " ('bologna', 2),\n",
       " ('sandwich.', 2),\n",
       " ('following.', 2),\n",
       " ('after.', 2),\n",
       " ('fence', 2),\n",
       " ('dog.', 2),\n",
       " ('licks', 2),\n",
       " ('sandwich', 2),\n",
       " ('play+ground', 2),\n",
       " ('finally', 2),\n",
       " ('under', 2),\n",
       " ('doing', 2),\n",
       " ('task', 2),\n",
       " ('objects', 2),\n",
       " ('experimenting', 2),\n",
       " ('et', 2),\n",
       " ('lots_of', 2),\n",
       " ('music', 2),\n",
       " ('static', 2),\n",
       " ('loud', 2),\n",
       " ('goes', 2),\n",
       " ('optional', 2),\n",
       " ('(lunch', 2),\n",
       " ('time:', 2),\n",
       " (\"julia's\", 2),\n",
       " ('stories)', 2),\n",
       " ('call', 2),\n",
       " ('middle', 2),\n",
       " ('usually', 2),\n",
       " ('puppets.', 2),\n",
       " ('giant', 2),\n",
       " ('truck.', 2),\n",
       " ('magnetic', 2),\n",
       " ('miniature', 2),\n",
       " ('highchair', 2),\n",
       " ('understand.', 2),\n",
       " ('eat.', 2),\n",
       " ('preoccupied', 2),\n",
       " ('mother.', 2),\n",
       " ('teach', 2),\n",
       " ('cooperative.', 2),\n",
       " ('secondsession', 1),\n",
       " ('thirdsession', 1),\n",
       " ('maternalinterview', 1),\n",
       " ('record', 1),\n",
       " ('sample', 1),\n",
       " ('taken', 1),\n",
       " ('\"reading\"', 1),\n",
       " ('caring', 1),\n",
       " ('dreams', 1),\n",
       " ('houses', 1),\n",
       " ('air', 1),\n",
       " ('boats', 1),\n",
       " ('dancing', 1),\n",
       " ('trees', 1),\n",
       " ('moves', 1),\n",
       " ('rapid', 1),\n",
       " ('pace.', 1),\n",
       " ('paul.', 1),\n",
       " ('hour.', 1),\n",
       " ('doorway', 1),\n",
       " ('hours.', 1),\n",
       " ('stays', 1),\n",
       " ('went', 1),\n",
       " ('sleep.', 1),\n",
       " ('windows', 1),\n",
       " ('closed', 1),\n",
       " ('bathtime', 1),\n",
       " ('bedtime.', 1),\n",
       " ('observer', 1),\n",
       " ('downstairs', 1),\n",
       " ('opening', 1),\n",
       " ('2/3', 1),\n",
       " ('\"on', 1),\n",
       " ('spot\"', 1),\n",
       " ('mechanical', 1),\n",
       " ('troubles', 1),\n",
       " ('impossible', 1),\n",
       " ('transcribe.', 1),\n",
       " ('1/3', 1),\n",
       " ('record:', 1),\n",
       " ('hour;', 1),\n",
       " ('shorter', 1),\n",
       " ('boundaries', 1),\n",
       " ('distinct', 1),\n",
       " ('precedinig', 1),\n",
       " ('fourth', 1),\n",
       " ('cecelia', 1),\n",
       " ('serving', 1),\n",
       " ('drinks', 1),\n",
       " ('cooler', 1),\n",
       " ('family.', 1),\n",
       " ('arrived.', 1),\n",
       " ('woke', 1),\n",
       " ('carried', 1),\n",
       " ('rocked', 1),\n",
       " ('minutes.', 1),\n",
       " ('film', 1),\n",
       " ('editor', 1),\n",
       " ('rolls', 1),\n",
       " ('film.', 1),\n",
       " ('sent', 1),\n",
       " ('entertaining', 1),\n",
       " ('visitor', 1),\n",
       " ('sorts', 1),\n",
       " ('colors,', 1),\n",
       " ('fails', 1),\n",
       " ('use', 1),\n",
       " ('color', 1),\n",
       " ('names', 1),\n",
       " ('appropriately.', 1),\n",
       " ('occasions', 1),\n",
       " ('clearly', 1),\n",
       " ('said', 1),\n",
       " ('\"fraser', 1),\n",
       " ('came.\"', 1),\n",
       " ('teething', 1),\n",
       " ('troubles.', 1),\n",
       " ('becoming', 1),\n",
       " ('jealous', 1),\n",
       " ('irritable', 1),\n",
       " ('wakened', 1),\n",
       " ('going', 1),\n",
       " ('apple', 1),\n",
       " ('doll', 1),\n",
       " ('falls', 1),\n",
       " ('absent.', 1),\n",
       " ('fraser', 1),\n",
       " ('buy', 1),\n",
       " ('bucket', 1),\n",
       " ('shovel', 1),\n",
       " ('eve.', 1),\n",
       " ('initially', 1),\n",
       " ('shy', 1),\n",
       " ('hides', 1),\n",
       " ('singing', 1),\n",
       " ('bouncing', 1),\n",
       " ('knee', 1),\n",
       " ('sings', 1),\n",
       " ('despite', 1),\n",
       " ('quality', 1),\n",
       " ('poor', 1),\n",
       " ('spots.', 1),\n",
       " ('husband', 1),\n",
       " ('girlfriend', 1),\n",
       " ('arriving', 1),\n",
       " ('delayed.', 1),\n",
       " ('milk.', 1),\n",
       " ('lazy', 1),\n",
       " ('pajamas.', 1),\n",
       " ('undressing', 1),\n",
       " ('on.', 1),\n",
       " ('bugs_bunny', 1),\n",
       " ('pulling', 1),\n",
       " ('\"talk\".', 1),\n",
       " ('awake', 1),\n",
       " ('alert', 1),\n",
       " ('cereal', 1),\n",
       " ('shows', 1),\n",
       " ('pictures', 1),\n",
       " ('identify', 1),\n",
       " ('snack', 1),\n",
       " ('tabloid', 1),\n",
       " ('newspapers', 1),\n",
       " ('playing-in-the-kitchen', 1),\n",
       " ('home.', 1),\n",
       " ('son', 1),\n",
       " ('dri', 1),\n",
       " ('where', 1),\n",
       " ('available.', 1),\n",
       " ('\"nana\"', 1),\n",
       " ('off.', 1),\n",
       " ('mikes.', 1),\n",
       " ('suggests', 1),\n",
       " ('do', 1),\n",
       " ('six', 1),\n",
       " ('mikes', 1),\n",
       " ('nine-year-old', 1),\n",
       " ('speaks.', 1),\n",
       " ('kenneth', 1),\n",
       " ('mckinnon', 1),\n",
       " ('accompanies', 1),\n",
       " ('observer.', 1),\n",
       " ('curlers.', 1),\n",
       " ('cornflakes.', 1),\n",
       " ('faces', 1),\n",
       " ('eating.', 1),\n",
       " ('woken', 1),\n",
       " ('up.', 1),\n",
       " ('week-end', 1),\n",
       " ('got', 1),\n",
       " ('pocketbook', 1),\n",
       " ('phenobarbitol', 1),\n",
       " ('pills.', 1),\n",
       " ('rushed', 1),\n",
       " ('hospital', 1),\n",
       " ('overnight', 1),\n",
       " ('\"is', 1),\n",
       " ('now', 1),\n",
       " ('normal\".', 1),\n",
       " ('volume', 1),\n",
       " ('low', 1),\n",
       " ('probably', 1),\n",
       " ('asking', 1),\n",
       " ('questions', 1),\n",
       " ('if', 1),\n",
       " ('experience.', 1),\n",
       " ('whether', 1),\n",
       " ('becouse', 1),\n",
       " ('add', 1),\n",
       " ('stimulation', 1),\n",
       " ('verbally', 1),\n",
       " ('non-verbally.', 1),\n",
       " ('espresses', 1),\n",
       " ('annoyance', 1),\n",
       " ('weeks', 1),\n",
       " ('skipped', 1),\n",
       " ('german', 1),\n",
       " ('measles', 1),\n",
       " ('trouble', 1),\n",
       " ('mike.', 1),\n",
       " ('least', 1),\n",
       " ('tapes', 1),\n",
       " ('april', 1),\n",
       " ('feared', 1),\n",
       " ('sleepy.', 1),\n",
       " ('fish', 1),\n",
       " ('constitutes', 1),\n",
       " ('kind', 1),\n",
       " ('experimental', 1),\n",
       " ('tried', 1),\n",
       " ('elicit', 1),\n",
       " ('include', 1),\n",
       " ('prepositions', 1),\n",
       " ('progressive', 1),\n",
       " ('verb', 1),\n",
       " ('forms.', 1),\n",
       " ('adult', 1),\n",
       " ('writing', 1),\n",
       " ('pencil', 1),\n",
       " ('papaer', 1),\n",
       " ('him.', 1),\n",
       " ('men', 1),\n",
       " ('michael', 1),\n",
       " ('killed', 1),\n",
       " ('weekend', 1),\n",
       " ('putting', 1),\n",
       " ('bobby+pins.', 1),\n",
       " ('bread', 1),\n",
       " ('unhooked', 1),\n",
       " ('ready', 1),\n",
       " ('get', 1),\n",
       " ('bath+tub.', 1),\n",
       " ('quickly', 1),\n",
       " ('bath+room', 1),\n",
       " ('wollensak', 1),\n",
       " ('hanging', 1),\n",
       " ('medicine', 1),\n",
       " ('chest.', 1),\n",
       " ('bath+tub', 1),\n",
       " ('keeping', 1),\n",
       " ('company.', 1),\n",
       " ('ill', 1),\n",
       " ('twice', 1),\n",
       " ('length.', 1),\n",
       " ('bed+room.', 1),\n",
       " ('supper', 1),\n",
       " ('20', 1),\n",
       " ('ends.', 1),\n",
       " ('driving', 1),\n",
       " ('newton.', 1),\n",
       " ('fell', 1),\n",
       " ('car.', 1),\n",
       " ('whining', 1),\n",
       " ('cranky', 1),\n",
       " ('preceeding', 1),\n",
       " ('39', 1),\n",
       " ('masked', 1),\n",
       " ('revere', 1),\n",
       " ('beach.', 1),\n",
       " ('ellen', 1),\n",
       " ('goldman', 1),\n",
       " ('research', 1),\n",
       " ('assistant', 1),\n",
       " ('cognitive', 1),\n",
       " ('center', 1),\n",
       " ('annex', 1),\n",
       " ('accompanied', 1),\n",
       " ('hum', 1),\n",
       " ('clear', 1),\n",
       " ('half-hour', 1),\n",
       " ('recordings', 1),\n",
       " ('first.', 1),\n",
       " ('41', 1),\n",
       " ('intermission.', 1),\n",
       " ('wireless', 1),\n",
       " ('microphones.', 1),\n",
       " ('40.', 1),\n",
       " (\"courtney's\", 1),\n",
       " ('therefore', 1),\n",
       " ('benefit', 1),\n",
       " ('any', 1),\n",
       " ('on-the-spot', 1),\n",
       " ('barnes', 1),\n",
       " (\"noah's\", 1),\n",
       " ('ark', 1),\n",
       " ('contains', 1),\n",
       " ('carved', 1),\n",
       " ('hughes', 1),\n",
       " ('eleven', 1),\n",
       " (\"o'clock.\", 1),\n",
       " ('errand', 1),\n",
       " ('indicated', 1),\n",
       " ('below', 1),\n",
       " ('11:00', 1),\n",
       " ('fluffed', 1),\n",
       " ('tissues', 1),\n",
       " ('cradle', 1),\n",
       " ('orange', 1),\n",
       " ('juice', 1),\n",
       " ('pounded', 1),\n",
       " ('settled', 1),\n",
       " ('themselves', 1),\n",
       " ('midst', 1),\n",
       " ('draw', 1),\n",
       " ('wandered', 1),\n",
       " ('already', 1),\n",
       " ('depositing', 1),\n",
       " ('mr', 1),\n",
       " ('ears', 1),\n",
       " ('mail', 1),\n",
       " ('catalogue', 1),\n",
       " ('learning', 1),\n",
       " (\"abc's\", 1),\n",
       " ('letters', 1),\n",
       " ('adults', 1),\n",
       " ('gathered', 1),\n",
       " ('soaking', 1),\n",
       " ('bruised', 1),\n",
       " ('finger', 1),\n",
       " ('cup', 1),\n",
       " ('barks', 1),\n",
       " ('uncle', 1),\n",
       " ('barking', 1),\n",
       " ('drowns', 1),\n",
       " ('eraso', 1),\n",
       " ('model', 1),\n",
       " ('pushing', 1),\n",
       " ('button', 1),\n",
       " ('retracts', 1),\n",
       " ('slate', 1),\n",
       " ('lifting', 1),\n",
       " ('transparent', 1),\n",
       " ('exploring', 1),\n",
       " ('cabinet', 1),\n",
       " ('alarm', 1),\n",
       " ('clock.', 1),\n",
       " ('\"connect', 1),\n",
       " ('dots\"', 1),\n",
       " ('request', 1),\n",
       " ('climbs', 1),\n",
       " ('bird', 1),\n",
       " ('cage', 1),\n",
       " ('exits', 1),\n",
       " ('shut', 1),\n",
       " ('begins.', 1),\n",
       " ('ducks', 1),\n",
       " ('pickle', 1),\n",
       " ('robin', 1),\n",
       " ('joanne', 1),\n",
       " ('peanut+butter', 1),\n",
       " ('sandwiches', 1),\n",
       " ('rolled', 1),\n",
       " ('linoleum', 1),\n",
       " ('surfacing', 1),\n",
       " ('modeling', 1),\n",
       " ('clay', 1),\n",
       " ('washes', 1),\n",
       " ('starts.', 1),\n",
       " ('helicopter', 1),\n",
       " ('dolls', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cp.pprint(get_labels('activities'))\n",
    "\n",
    "# for corpus in corpus_set:\n",
    "#     for labels in get_labels('activities')[corpus]:\n",
    "#         if 'reading' in labels:\n",
    "#             print(corpus)\n",
    "            \n",
    "keywords = []            \n",
    "for f in data_idx.situation:\n",
    "    keywords.extend(f.lower().split())\n",
    "\n",
    "Counter(keywords).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d1660-df93-4e7c-9c18-bda45fd7c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_idx.file_path[data_idx.corpus=='Bernstein']\n",
    "reader = pylangacq.Reader.from_files(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76527ab7-818e-4565-a5cd-055437f93ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame()\n",
    "group_df['name'] = [reader.headers()[file]['Participants']['CHI']['name'] for file in range(len(f))]\n",
    "group_df['group'] = [reader.headers()[file]['Participants']['CHI']['group'] for file in range(len(f))]\n",
    "group_df['participants'] = [reader.participants(by_files=True)[file] for file in range(len(f))]\n",
    "group_df['mot_edu'] = [reader.headers()[file]['Participants']['CHI']['education'] for file in range(len(f))]\n",
    "group_df['situation'] = [reader.headers()[file]['Situation'] for file in range(len(f))]\n",
    "group_df['type'] = [reader.headers()[file]['Types'] for file in range(len(f))]\n",
    "\n",
    "group_df\n",
    "\n",
    "# reader.tokens(participants='CHI', by_files=True)[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67aa1b-ec20-48cd-9795-d4d3b5835e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader[3].headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de4943-30a3-4d47-9312-c6f87b3f5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader[0].headers()[0]['Situation'] if reader[0].headers()[0]['Situation'] else 0\n",
    "\n",
    "if reader[0].headers()[0]['Situation']: print(reader[0].headers()[0]['Situation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87dc52-1d56-47ab-a204-c61a63b49887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6049e1-20e8-4e47-a436-72cec689a415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
